# when using relative paths: note that the working directory is the pwd of the terminal from where snakemake is run,
# this should be .../spapros-smk  (also possible: .../spapros-smk/workflow, might mess things up though)
DATA_DIR: /lustre/groups/ml01/workspace/lena.strasser/MA/benchmarking/data/test_data/permut_data
DATA_DIR_TMP: /lustre/groups/ml01/workspace/lena.strasser/spapros-smk/data/tmp_data
RESULTS_DIR: results
SAVE_METHOD_SPECIFIC_OUTPUT: True # Whether to save method specific output of the selection methods (will be in RESULTS_DIR+"method_specific/{run}/")
PRELIMINARY_EVAL_SUMMARY: False # Whether to just summarise the currently available evaluation results and not run anything else.
# NOTE: PRELIMINARY_EVAL_SUMMARY can lead to wrong values for set ids that partially miss evaluation files!!!

selections:
  batch_one_dataset_HLCA:
    datasets: [ HLCA ]
    dataset_param:
      processing: [ lognorm ]
      permutations: [ /lustre/groups/ml01/workspace/lena.strasser/MA/benchmarking/data/test_data/permut_data/HLCA_permut_one.csv ]
      ct_key: [ cell_type ]
    selection_param:
      n: [25, 50, 100, 200, 500, 1000, 2000, 3000, 4000, 5000, 6000, 7000]
      method_specific_processing: [ False ]
      ct_key: [ cell_type ]
      batch_key: [ donor_id ] # the default behaviour is batch_key=None
    methods:
      spapros
  batch_pseudo_HLCA:
    datasets: [ HLCA ]
    dataset_param:
      processing: [ lognorm ]
      permutations: [ /lustre/groups/ml01/workspace/lena.strasser/MA/benchmarking/data/test_data/permut_data/HLCA_permut_one.csv ]
      ct_key: [ cell_type ]
    selection_param:
      n: [ 8000 ]
      method_specific_processing: [ False ]
      ct_key: [ cell_type ]
      batch_key: [ donor_id ] # the default behaviour is batch_key=None
    methods:
      pseudo

evaluations:
 eval_var_one_HLCA:
   batches: [ batch_one_dataset_HLCA, batch_pseudo_HLCA]
   selection_dataset: False
   datasets: [ HLCA ]
   dataset_param:
     processing: [ lognorm ]
     permutations: [ /lustre/groups/ml01/workspace/lena.strasser/MA/benchmarking/data/test_data/permut_data/HLCA_permut_one.csv ]
     ct_key: [ cell_type ]
   metrics: [ forest_clfs, knn_overlap_X_donor_id, cluster_similarity, knn_overlap ]  # [forest_clfs, gene_corr, cluster_similarity, knn_overlap_X]
  eval_on_full_HLCA:
    batches: [ batch_one_dataset_HLCA, batch_pseudo_HLCA ]
    selection_dataset: False
    datasets: [ HLCA ]
    dataset_param:
      processing: [ lognorm ]
      ct_key: [ cell_type ]
    metrics: [ forest_clfs, knn_overlap_X_donor_id, cluster_similarity, knn_overlap ]  # forest_clfs, gene_corr, cluster_similarity, knn_overlap_X]